{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning LAB 3: CLUSTERING - K-means and linkage-based clustering\n",
    "\n",
    "Course 2023/24: *M. Caligiuri*, *P. Talli*, *F. Lincetto*, *F. Chiariotti*, *P. Zanuttigh*\n",
    "\n",
    "The notebook contains some simple tasks about **CLUSTERING**.\n",
    "\n",
    "Complete all the **required code sections** and **answer to all the questions**.\n",
    "\n",
    "### IMPORTANT for the evaluation score:\n",
    "\n",
    "1. **Read carefully all cells** and **follow the instructions**.\n",
    "2. **Re-run all the code from the beginning** to obtain the results for the final version of your notebook, since this is the way we will do it before evaluating your notebooks.\n",
    "3. Make sure to fill the code in the appropriate places **without modifying the template**, otherwise you risk breaking later cells.\n",
    "4. Please **submit the jupyter notebook file (.ipynb)**, do not submit python scripts (.py) or plain text files. **Make sure that it runs fine with the restat&run all command**.\n",
    "5. **Answer the questions in the appropriate cells**, not in the ones where the question is presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation with k-means\n",
    "\n",
    "In this laboratory we will use the k-means algorithm to cluster a dataset of 3D points. We will apply **K-means** to the problem of image compression and image segmentation. The main idea is to apply k-means to the colors of the pixels of an image to select the k most representative colors. Then, we will replace each pixel color with the closest representative color. This will allow us to reduce the number of colors in the image and compress it. A color is a vector of 3 values (R,G,B) that represent the amount of red, green and blue in the color; this implies that each pixel is a point in a 3D space.\n",
    "\n",
    "In particular you are going to implement the k-means algorithm from scratch and to compare the results with the implementation already present in the sklearn library.\n",
    "\n",
    "In the second part of the laboratory we will use a **linkage-based** clustering algorithm to cluster a dataset of 2D points and compare it with the results obtained with k-means.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary step\n",
    "\n",
    "Place your **name** and **ID number** (matricola) in the cell below. <br>\n",
    "Also recall to **save the file as Surname_Name_LAB02.ipynb**, failure to do so will incur in a **lower grade**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student name**: Pietro Bernardi\n",
    "\n",
    "**ID Number**: 2097494"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the necessary Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import typing as tp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the heplper functions\n",
    "\n",
    "In this section you will find some helper functions (some already implemented, some to be implemented by you) that will be used in the following sections.\n",
    "1. `img_plot` -> function to plot an image with name and dimension as title,\n",
    "2. `scatter_plot` -> function to plot a scatter plot of the data,\n",
    "3. `scatter_plot_2d` -> function to plot a 2D scatter plot of the data,\n",
    "4. `error_plot` -> function to plot the error of the k-means algorithm over the iterations,\n",
    "5. `cluster_plot` -> function to plot the obtained clusters.\n",
    "\n",
    "**DO NOT CHANGE THE PRE-WRITTEN CODE UNLESS OTHERWISE SPECIFIED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_plot(img: np.ndarray, title: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Plot an image\n",
    "    :param img: image to plot\n",
    "    :param title: title of the plot\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    if title is not None:\n",
    "        plt.title(f'{title}: {img.shape}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(data: np.ndarray, clusters: np.ndarray = None, centers: np.ndarray = None, title: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Plot a scatter plot of the data\n",
    "    :param data: data to plot\n",
    "    :param clusters: cluster labels\n",
    "    :param centers: cluster centers\n",
    "    :param title: title of the plot\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    axis = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "    axis.set_xlabel(\"Red\")\n",
    "    axis.set_ylabel(\"Green\")\n",
    "    axis.set_zlabel(\"Blue\", rotation=90, labelpad=-1)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    if clusters is None:\n",
    "        axis.scatter(data[:,0], data[:,1], data[:,2], marker=\"o\", c=data, s=5)\n",
    "    else:\n",
    "        axis.scatter(data[:,0], data[:,1], data[:,2], marker=\"o\", c=clusters, s=1, cmap='viridis', zorder=0, alpha=0.5 )\n",
    "    if centers is not None:\n",
    "        axis.scatter(centers[:,0], centers[:,1], centers[:,2], c='red', s=400, zorder=10)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot_2d(x: np.ndarray, y: np.ndarray = None, centers: np.ndarray = None, title: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Plot a scatter plot of the data\n",
    "    :param x: data to plot\n",
    "    :param y: cluster labels\n",
    "    :param centers: cluster centers\n",
    "    :param title: title of the plot\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(x[:,0], x[:,1], c=y, marker=\"o\", s=10, cmap='viridis')\n",
    "    if centers is not None:\n",
    "        plt.scatter(centers[:,0], centers[:,1], c='black', s=200, alpha=0.5)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plot(errors: np.ndarray, labels: np.ndarray = None) -> None:\n",
    "    \"\"\"\n",
    "    Plot the errors over the iterations\n",
    "    :param errors: errors to plot\n",
    "    \"\"\"\n",
    "    \n",
    "    if labels is None:\n",
    "        plt.plot(errors[1:-1])\n",
    "        plt.plot(errors[1:-1], 'ro')\n",
    "    else:\n",
    "        plt.plot(labels, errors)\n",
    "        plt.plot(labels, errors, 'ro')\n",
    "    plt.title('Error over iterations')\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('Iteration #')\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_plot(labels: np.ndarray, x: np.ndarray, title: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Plot the clusters\n",
    "    :param labels: cluster labels\n",
    "    :param x: data\n",
    "    :param title: title of the plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Black removed and is used for noise instead.\n",
    "    unique_labels = set(labels)\n",
    "    colors = [plt.cm.Spectral(each)\n",
    "            for each in np.linspace(0, 1, len(unique_labels))]\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            # Black used for noise.\n",
    "            col = [0, 0, 0, 1]\n",
    "\n",
    "        class_member_mask = (labels == k)\n",
    "\n",
    "        xy = x[class_member_mask ]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                markeredgecolor='k', markersize=14)\n",
    "\n",
    "        xy = x[class_member_mask ]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                markeredgecolor='k', markersize=6)\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADDED\n",
    "def inertia_plot(inertia: np.ndarray, labels: np.ndarray=None) -> None:\n",
    "    if labels is None:\n",
    "        plt.plot(inertia[1:-1])\n",
    "        plt.plot(inertia[1:-1], 'ro')\n",
    "    else:\n",
    "        plt.plot(labels, inertia)\n",
    "        plt.plot(labels, inertia, 'ro')\n",
    "    plt.title('Error over k')\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('k #')\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADDED\n",
    "def sklearn_plottable(img: np.ndarray, n: int) -> np.ndarray:\n",
    "    n_pixels = img.shape[0]*img.shape[1]\n",
    "    matrix_columns = []\n",
    "    for i in range(n):\n",
    "        matrix_columns.append(img[:,:,i].reshape(n_pixels,1)/255)\n",
    "    return np.hstack(matrix_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) K-means clustering\n",
    "\n",
    "### TO DO (A.0)\n",
    "    \n",
    "**Set** the random **seed** using your **ID**. If you need to change it for testing add a constant explicitly, eg.: 1234567 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix your ID (\"numero di matricola\") and the seed for random generator\n",
    "# as usual you can try different seeds by adding a constant to the number:\n",
    "# ID = 1234567 + X\n",
    "ID = 2097494  # insert your ID number here\n",
    "np.random.seed(ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the provided images and display them (if you like you can experiment with other images)\n",
    "# To load the images use the function plt.imread(<path_to_iamge>)\n",
    "# ADD YOUR CODE HERE\n",
    "img_landscape = plt.imread(\"./data/landscape.jpg\")\n",
    "img_reindeer = plt.imread(\"./data/reindeer.jpg\")\n",
    "img_santa = plt.imread(\"./data/santaclaus2.jpg\")\n",
    "\n",
    "# Plot the images with their shapes\n",
    "# Sugestion: use the function img_plot()\n",
    "# ADD YOUR CODE HERE\n",
    "img_plot(img_landscape, title=\"Landscape.jpg\")\n",
    "img_plot(img_reindeer, title=\"reindeer.jpg\")\n",
    "img_plot(img_santa, title=\"santa.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start by using the Santa Claus image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to a matrix of num_pixels x 3 \n",
    "# (divide by 255 to have colors in [0 1] range for plotting functions of sklearn)\n",
    "# ADD YOUR CODE HERE\n",
    "img_reshaped_santa = sklearn_plottable(img_santa, 3)\n",
    "minim = np.min(img_reshaped_santa)\n",
    "maxim = np.max(img_reshaped_santa)\n",
    "\n",
    "# Print the shape of the data and the min and max values of the pixels\n",
    "# ADD YOUR CODE HERE\n",
    "print(f\"Shape: {img_reshaped_santa.shape}\")\n",
    "print(f\"Min value of pixels: {minim}\")\n",
    "print(f\"Max value of pixels: {maxim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the points in the 3-dimensional space with normalized intervals between 0 and 1 (corresponding to the three channels of the image, i.e. Red Green and Blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sugestion: use the function scatter_plot()\n",
    "# ADD YOUR CODE HERE\n",
    "scatter_plot(img_reshaped_santa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (A.1)\n",
    "Implement the k-means algorithm manually (**do not use the kmeans function of sklearn and do not download implementations from other web sources**). The inputs to the function is the set of vectors to be clustered and the number of clusters. The output must contain the clusters barycenters, a vector associating each data point to the corresponding cluster and the error (value of the cost function) at each iteration.\n",
    "Additionally, fix a maximum number of iterations of the k-means algorithm (e.g., 50).\n",
    "\n",
    "Be careful about the initalization, you can use some random points from the training set, or get random values but ensure they are in the proper range. Poor initalizations can lead to the failure of the algorithm (in particular check that no cluster is initialized as empty, otherwise the algorithm can not update it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_kmeans(points: np.ndarray, k: int, max_iters: int = 50) -> tp.Tuple[np.ndarray, np.ndarray, list]:\n",
    "    \"\"\"\n",
    "    Perform K-means clustering\n",
    "    :param points: data points\n",
    "    :param k: number of clusters\n",
    "    :param max_iters: maximum number of iterations\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate random centers\n",
    "    # use sigma and mean to ensure it represent the whole data\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    centroids_idxs = np.random.choice(points.shape[0], k, replace=False)\n",
    "    centroids = points[centroids_idxs]\n",
    "    clusters = [[] for _ in range(k)]\n",
    "    \n",
    "    prev_error = 100000\n",
    "    error = [9999]\n",
    "    \n",
    "    # Iterate until the estimate of that center stays the same or max iteration are reached\n",
    "    iters = 0\n",
    "    while (error[iters] != prev_error) and iters < max_iters:\n",
    "        # Measure the distance to every center\n",
    "        # ADD YOUR CODE HERE\n",
    "        distances = [np.sqrt(np.sum((x-centroids)**2,axis=1)) for x in points]\n",
    "   \n",
    "        # Assign all training data to closest center\n",
    "        # ADD YOUR CODE HERE\n",
    "        clusters_idxs = np.array([np.argmin(d) for d in distances])\n",
    "        clusters = [points[clusters_idxs==i_k] for i_k in range(k)]\n",
    "        \n",
    "        # Checking at the first iteration if the clusters are not empty\n",
    "        if iters==0:\n",
    "            retry = True\n",
    "            while retry:\n",
    "                retry = False\n",
    "                for i in range(k):\n",
    "                    if clusters[i].shape[0]==0:\n",
    "                        # this cluster is empty so\n",
    "                        retry = True\n",
    "                        break;\n",
    "                if retry:\n",
    "                    # re-generating the centers\n",
    "                    centroids_idxs = np.random.choice(points.shape[0], k, replace=False)\n",
    "                    centroids = points[centroids_idxs]\n",
    "                    # re-calculating distances\n",
    "                    distances = [np.sqrt(np.sum((x-centroids)**2,axis=1)) for x in points]\n",
    "                    # re-calculating clusters\n",
    "                    clusters_idxs = np.array([np.argmin(d) for d in distances])\n",
    "                    clusters = [points[clusters_idxs==i_k] for i_k in range(k)]\n",
    "        \n",
    "        # Calculate mean for every cluster and update the center\n",
    "        # ADD YOUR CODE HERE\n",
    "        centroids = np.array([np.mean(clust,axis=0) for clust in clusters])\n",
    "        \n",
    "        # Update the error\n",
    "        # ADD YOUR CODE HERE\n",
    "        g_m = [np.sum([np.sum((x-centroids[i_k])**2,axis=0) for x in clusters[i_k]]) for i_k in range(3)]\n",
    "        g_km = np.sum(g_m)\n",
    "        error.append(g_km)\n",
    "        if (iters>=1):\n",
    "            prev_error = error[iters-1]\n",
    "        \n",
    "        # Update the iteration counter\n",
    "        iters += 1\n",
    "\n",
    "    return centroids, clusters_idxs, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (A.2)\n",
    "\n",
    "Now try the function you developed on the Santaclaus image with three clusters (k=3). \n",
    "\n",
    "Then plot the data points in the 3-dimensional space, each point must be coloured based on the membership to one of the clusters. Additionally, plot the respective clusters centroids (use a different shape, size or color to highlight the centroids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your K-means function on the data\n",
    "# ADD YOUR CODE HERE\n",
    "centroids, clusters_idxs, error = my_kmeans(img_reshaped_santa, 3, max_iters=100)\n",
    "\n",
    "# Print the errors:\n",
    "# ADD YOUR CODE HERE\n",
    "print(\"-\"*18)\n",
    "print(\"N.ITER.  ERROR\")\n",
    "print(\"-\"*18)\n",
    "for idx, v in enumerate(error):\n",
    "    print(idx,'\\t',round(v,4))\n",
    "print(\"-\"*18)\n",
    "\n",
    "# Plot the results\n",
    "# ADD YOUR CODE HERE\n",
    "scatter_plot(img_reshaped_santa, clusters_idxs, centroids, title=\"3d scatter plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (A.3) \n",
    "Plot the value of the error versus the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sugestion: use the function error_plot()\n",
    "# ADD YOUR CODE HERE\n",
    "error_plot(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (A.4)\n",
    "Now use the k-means function provided in sklearn. Pass to the function the number of clusters and use multiple random initializations (n_init parameter). Go to the documentation page for further details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-means model\n",
    "# ADD YOUR CODE HERE\n",
    "kmeans = KMeans(n_clusters=3, n_init=\"auto\")\n",
    "\n",
    "# Fit the model to the data\n",
    "# ADD YOUR CODE HERE\n",
    "kmeans.fit(img_reshaped_santa)\n",
    "\n",
    "# Get the cluster centers\n",
    "# ADD YOUR CODE HERE\n",
    "kmeans_centroids = kmeans.cluster_centers_\n",
    "kmeans_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same plot as above but with the output of the k-means function provided in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE\n",
    "scatter_plot(img_reshaped_santa, kmeans_labels, kmeans_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (A.Q1) [Answare the following] \n",
    "\n",
    "Compare the results obtained with your implementation and with k-means from sklearn. Do you observe any differences, *i.e.*, do the two plots match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER A.Q1:** The two plots match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (A.5)\n",
    "\n",
    "Now display the segmented image based on the two clusters found above with the k-means functions by sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extarct the color values of the centers\n",
    "# ADD YOUR CODE HERE\n",
    "kmeans_colors = np.array(np.round(kmeans_centroids*255,0), dtype='int')\n",
    "\n",
    "# Reshape the data to the original image shape\n",
    "# ADD YOUR CODE HERE\n",
    "kmeans_img_reshaped_santa_recolored = np.array([kmeans_colors[pxlabel] for pxlabel in kmeans_labels])\n",
    "kmeans_img_santa_recolored = kmeans_img_reshaped_santa_recolored.reshape(img_santa.shape)\n",
    "\n",
    "# Plot the recolored image\n",
    "# ADD YOUR CODE HERE\n",
    "img_plot(kmeans_img_santa_recolored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now display the segmented image based on the two clusters found above with the k-means functions implemented by yourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extarct the color values of the centers\n",
    "# ADD YOUR CODE HERE\n",
    "colors = np.array(np.round(centroids*255,0), dtype='int')\n",
    "\n",
    "# Reshape the data to the original image shape\n",
    "# ADD YOUR CODE HERE\n",
    "img_reshaped_santa_recolored = np.array([colors[pxlabel] for pxlabel in clusters_idxs])\n",
    "img_santa_recolored = img_reshaped_santa_recolored.reshape(img_santa.shape)\n",
    "\n",
    "# Plot the recolored image\n",
    "# ADD YOUR CODE HERE\n",
    "img_plot(img_santa_recolored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (A.Q2) [Answare the following]\n",
    "\n",
    "What do you observe? Do you think clustering is useful for image segmenation? And for image compression? Comment your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER A.Q2:** I would say that it is useful for image compression (lossy) since the algorithm recolors the image using a number of colors that is equal to the number of clusters, thus reducing the original color space. When it comes to image segmentation, I would say that it strongly depends on the nature of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (A.6)\n",
    "\n",
    "Now load the landscape image (optional: try also with the reindeer image) and segment it using kmeans with k varying from 2 to 15 clusters. You can use the sklearn implementation.\n",
    "\n",
    "Then plot the resulting data points in the 3-dimensional space, each point must be colored based on the cluster membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reshape the data to a matrix of total_num_pixels x 3\n",
    "# ADD YOUR CODE HERE\n",
    "img_reshaped_landscape = sklearn_plottable(img_landscape, 3)\n",
    "\n",
    "# Print the shape of the data and the min and max values of the pixels\n",
    "# ADD YOUR CODE HERE\n",
    "minim = np.min(img_reshaped_landscape)\n",
    "maxim = np.max(img_reshaped_landscape)\n",
    "print(f\"Shape: {img_reshaped_landscape.shape}\")\n",
    "print(f\"Min value of pixels: {minim}\")\n",
    "print(f\"Max value of pixels: {maxim}\")\n",
    "\n",
    "# Cycle over different values of K and plot the results for each value\n",
    "print('\\nK-means clustering with different values of K (2-15):')\n",
    "inertia = list()\n",
    "\n",
    "for k in range(2,16):\n",
    "    # Define the K-means model\n",
    "    # ADD YOUR CODE HERE\n",
    "    kmeans_landscape = KMeans(n_clusters=k, n_init=\"auto\")\n",
    "\n",
    "    # Fit the model to the data\n",
    "    # ADD YOUR CODE HERE\n",
    "    kmeans_landscape.fit(img_reshaped_landscape)\n",
    "\n",
    "    # Get the cluster centers\n",
    "    # ADD YOUR CODE HERE\n",
    "    kmeans_landscape_centroids = kmeans_landscape.cluster_centers_\n",
    "    kmeans_landscape_labels = kmeans_landscape.labels_\n",
    "\n",
    "    # Extarct the color values of the centers\n",
    "    # ADD YOUR CODE HERE\n",
    "    kmeans_landscape_colors = np.array(np.round(kmeans_landscape_centroids*255,0), dtype='int')\n",
    "\n",
    "    # Reshape the data to the original image shape\n",
    "    # ADD YOUR CODE HERE\n",
    "    img_reshaped_landscape_recolored = np.array([kmeans_landscape_colors[pxlabel] for pxlabel in kmeans_landscape_labels])\n",
    "    img_landscape_recolored = img_reshaped_landscape_recolored.reshape(img_landscape.shape)\n",
    "\n",
    "    # Update the inertia\n",
    "    # ADD YOUR CODE HERE\n",
    "    inertia.append(kmeans_landscape.inertia_)\n",
    "    \n",
    "    # Plot the scatter plot and the ricolored imag\n",
    "    # ADD YOUR CODE HERE\n",
    "    scatter_plot(img_reshaped_landscape,kmeans_landscape_labels, kmeans_landscape_centroids, title=\"k=\"+str(k))\n",
    "    \n",
    "    # Plot the recolored image\n",
    "    # ADD YOUR CODE HERE (remove the pass statement)\n",
    "    img_plot(img_landscape_recolored, title=\"k=\"+str(k))\n",
    "    \n",
    "    print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (A.7)\n",
    "\n",
    "Plot for different values of k (e.g. k between 2 and 15) the respective error of the kmeans algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE\n",
    "inertia_plot(inertia, labels=range(2,16,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (AQ.3) [Answare the following]\n",
    "\n",
    "Compare the results with different values of k, what do you observe? \n",
    "\n",
    "Analyze also the error, which one do you think is the optimal value of k?\n",
    "\n",
    "Is there a single, clear answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER A.Q3:** as it is expected, the error decreases as k increases. However, the rate of descent begins to slow down firstly after k=3 and then again after k=6. So a reasonable tradeoff between error value and computation time could be k=6. Anyway it is difficult to point out a single answer clearly in this case. Regarding the recolored images, it is evident that after k=6 no major changes occurr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the reindeer image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reshape the data to a matrix of total_num_pixels x 3\n",
    "# ADD YOUR CODE HERE\n",
    "img_reshaped_reindeer = sklearn_plottable(img_reindeer, 3)\n",
    "\n",
    "# Print the shape of the data and the min and max values of the pixels\n",
    "# ADD YOUR CODE HERE\n",
    "minim = np.min(img_reshaped_reindeer)\n",
    "maxim = np.max(img_reshaped_reindeer)\n",
    "print(f\"Shape: {img_reshaped_reindeer.shape}\")\n",
    "print(f\"Min value of pixels: {minim}\")\n",
    "print(f\"Max value of pixels: {maxim}\")\n",
    "\n",
    "# Cycle over different values of K and plot the results for each value\n",
    "print('\\nK-means clustering with different values of K (2-15):')\n",
    "inertia_reindeer = list()\n",
    "\n",
    "for k in range(2,16):\n",
    "    # Define the K-means model\n",
    "    # ADD YOUR CODE HERE\n",
    "    kmeans_reindeer = KMeans(n_clusters=k, n_init=\"auto\")\n",
    "\n",
    "    # Fit the model to the data\n",
    "    # ADD YOUR CODE HERE\n",
    "    kmeans_reindeer.fit(img_reshaped_reindeer)\n",
    "\n",
    "    # Get the cluster centers\n",
    "    # ADD YOUR CODE HERE\n",
    "    kmeans_reindeer_centroids = kmeans_reindeer.cluster_centers_\n",
    "    kmeans_reindeer_labels = kmeans_reindeer.labels_\n",
    "\n",
    "    # Extarct the color values of the centers\n",
    "    # ADD YOUR CODE HERE\n",
    "    kmeans_reindeer_colors = np.array(np.round(kmeans_reindeer_centroids*255,0), dtype='int')\n",
    "\n",
    "    # Reshape the data to the original image shape\n",
    "    # ADD YOUR CODE HERE\n",
    "    img_reshaped_reindeer_recolored = np.array([kmeans_reindeer_colors[pxlabel] for pxlabel in kmeans_reindeer_labels])\n",
    "    img_reindeer_recolored = img_reshaped_reindeer_recolored.reshape(img_reindeer.shape)\n",
    "\n",
    "    # Update the inertia\n",
    "    # ADD YOUR CODE HERE\n",
    "    inertia_reindeer.append(kmeans_reindeer.inertia_)\n",
    "    \n",
    "    # Plot the scatter plot and the ricolored imag\n",
    "    # ADD YOUR CODE HERE\n",
    "    scatter_plot(img_reshaped_reindeer,kmeans_reindeer_labels, kmeans_reindeer_centroids, title=\"k=\"+str(k))\n",
    "    \n",
    "    # Plot the recolored image\n",
    "    # ADD YOUR CODE HERE (remove the pass statement)\n",
    "    img_plot(img_reindeer_recolored, title=\"k=\"+str(k))\n",
    "    \n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia_plot(inertia_reindeer, labels=range(2,16,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the rate of decrease of the error begins to slow down after k=5. This could represent an optimal value for k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Linkage-based clustering\n",
    "\n",
    "The second part of the assignment concern instead linkage-based clustering. We will use the AgglomerativeClustering module of sklearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (B.0)\n",
    "\n",
    "Load the sample dataset located at `data/moon_data.npz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "data = np.load(\"./data/moon_data.npz\") # ADD YOUR CODE HERE (use np.load())\n",
    "\n",
    "# Extract data\n",
    "x = data['X']\n",
    "labels_true = data['labels_true']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (B.1)\n",
    "\n",
    "Now exploit the AgglomerativeClustering algorithm from the sklearn library on the provided sample data points. Use the \"single\" linkage type that correspond to the minimum distance criteria seen in the lectures and 2 clusters. Notice that the \"single\" option has been introduced recently in sklearn, if you get an error ensure you have a recent version of the library. Plot the resulting clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Agglomerative Clustering\n",
    "# Define the Agglomerative Clustering model\n",
    "# ADD YOUR CODE HERE\n",
    "aggclust = AgglomerativeClustering(n_clusters=2, linkage='single', compute_distances=True)\n",
    "\n",
    "# Fit the model to the data\n",
    "# ADD YOUR CODE HERE\n",
    "aggclust.fit(x)\n",
    "\n",
    "# Compute the number of clusters in labels, ignoring noise if present.\n",
    "# ADD YOUR CODE HERE\n",
    "aggclust_labels = aggclust.labels_\n",
    "\n",
    "# Print the results\n",
    "# ADD YOUR CODE HERE\n",
    "print(f\"Number of clusters: {np.unique(aggclust_labels).shape[0]}\")\n",
    "print(f\"Labels: {aggclust_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot result \n",
    "# Sugestion: use the function cluster_plot()\n",
    "# ADD YOUR CODE HERE\n",
    "cluster_plot(aggclust_labels, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (B.2)\n",
    "\n",
    "Now try the KMeans with two clusters on the same dataset we used for the AgglomerativeClustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-means model\n",
    "# ADD YOUR CODE HERE\n",
    "kmeans_data = KMeans(n_clusters=2, n_init=\"auto\")\n",
    "\n",
    "# Fit the model to the data\n",
    "# ADD YOUR CODE HERE\n",
    "kmeans_data.fit(x)\n",
    "\n",
    "# Get the cluster centers\n",
    "# ADD YOUR CODE HERE\n",
    "kmeans_data_centroids = kmeans_data.cluster_centers_\n",
    "kmeans_data_labels = kmeans_data.labels_\n",
    "\n",
    "# Extarct the color values of the centers\n",
    "# ADD YOUR CODE HERE\n",
    "kmeans_data_colors = np.array(np.ceil(kmeans_reindeer_centroids*255), dtype='int')\n",
    "\n",
    "# Plot the results\n",
    "# Sugestion: use the function scatter_plot_2d()\n",
    "# ADD YOUR CODE HERE\n",
    "scatter_plot_2d(x, kmeans_data_labels, kmeans_data_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO (B.Q1) [Answare the following]\n",
    "\n",
    "Compare the results of K-means and Agglomerative Clustering and explain what you observe and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER B.Q1:** when using KMeans, the data is labelled into clusters and for each cluster, the center is optimized so that it's the closest to each other point of the cluster. This operation is done by minimizing the euclidean distance between the center and each of the cluster's points. So, each point lies on a hyper-sphere in sample space with its center on the cluster's center and the radius given by the point-center distance. This is not suitable for all datasets since not all datasets exhibit this kind of symmetry. This could lead to situations like the one above where the data is incorrectly labelled.\n",
    "\n",
    "Agglomerative clustering, instead, merges together clusters that are sufficiently close together. This allows the algorithm to be less dependent on the particular nature of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
